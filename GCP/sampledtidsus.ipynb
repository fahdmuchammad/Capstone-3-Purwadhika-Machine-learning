{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## imporrt libarary \n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#import google cloud library\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "# from google.cloud import aiplatform\n",
    "# from support_functions import missing_value, fill_missing, list_dtypes\n",
    "\n",
    "## sklearn module\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"trial_bigq.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = 'dtidsUS'\n",
    "dataset_id = 'capstone'\n",
    "table_id = 'data_telco_customer_churn'\n",
    "region = 'us-central1'\n",
    "bucket_name = 'modul4'\n",
    "blob_name = 'm_fahd/data_telco_customer_churn.csv'\n",
    "\n",
    "client = bigquery.Client(project='dtidsus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model succeeded\n"
     ]
    }
   ],
   "source": [
    "try : \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    data_capstone = bucket.blob('fahd/data_telco_customer_churn.csv')\n",
    "    data_capstone.upload_from_filename('data_telco_customer_churn.csv')\n",
    "\n",
    "    print (\"Uploading model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = bigquery.Client('dtidsus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_job = client.query(f\"\"\"select * from {dataset_id}.{table_id}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/google/cloud/bigquery/table.py:1727: UserWarning: BigQuery Storage module not found, fetch data with the REST endpoint instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = query_job.result().to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dependents</th>\n",
       "      <th>tenure</th>\n",
       "      <th>OnlineSecurity</th>\n",
       "      <th>OnlineBackup</th>\n",
       "      <th>InternetService</th>\n",
       "      <th>DeviceProtection</th>\n",
       "      <th>TechSupport</th>\n",
       "      <th>Contract</th>\n",
       "      <th>PaperlessBilling</th>\n",
       "      <th>MonthlyCharges</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>49</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>19.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>11</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>True</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>36</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>No internet service</td>\n",
       "      <td>One year</td>\n",
       "      <td>False</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Dependents  tenure       OnlineSecurity         OnlineBackup  \\\n",
       "0       False      49  No internet service  No internet service   \n",
       "1        True      13  No internet service  No internet service   \n",
       "2       False      11  No internet service  No internet service   \n",
       "3        True      11  No internet service  No internet service   \n",
       "4       False      36  No internet service  No internet service   \n",
       "\n",
       "  InternetService     DeviceProtection          TechSupport  Contract  \\\n",
       "0              No  No internet service  No internet service  One year   \n",
       "1              No  No internet service  No internet service  One year   \n",
       "2              No  No internet service  No internet service  One year   \n",
       "3              No  No internet service  No internet service  One year   \n",
       "4              No  No internet service  No internet service  One year   \n",
       "\n",
       "   PaperlessBilling  MonthlyCharges  Churn  \n",
       "0             False            19.0  False  \n",
       "1             False            20.0  False  \n",
       "2             False            20.0  False  \n",
       "3              True            20.0  False  \n",
       "4             False            20.0  False  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#cleansing \n",
    "# result = df.drop(['ID'], axis = 1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dependents          0\n",
       "tenure              0\n",
       "OnlineSecurity      0\n",
       "OnlineBackup        0\n",
       "InternetService     0\n",
       "DeviceProtection    0\n",
       "TechSupport         0\n",
       "Contract            0\n",
       "PaperlessBilling    0\n",
       "MonthlyCharges      0\n",
       "Churn               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result  = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.89      0.86       726\n",
      "         1.0       0.61      0.48      0.54       260\n",
      "\n",
      "    accuracy                           0.78       986\n",
      "   macro avg       0.72      0.69      0.70       986\n",
      "weighted avg       0.77      0.78      0.77       986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = result.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create a dictionary to store label encoders for each column\n",
    "encoders = {}\n",
    "\n",
    "# Iterate through categorical columns\n",
    "for col in categorical_cols:\n",
    "    # Create a LabelEncoder object for each column\n",
    "    encoder = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the column\n",
    "    result[col] = encoder.fit_transform(result[col])\n",
    "\n",
    "    # Store the encoder in the dictionary for later use\n",
    "    encoders[col] = encoder\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "y = result['Churn']  \n",
    "X = result.drop(['Churn'], axis=1)  \n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation\n",
    "predictions = model.predict(X_test)\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "# Save Model\n",
    "model_filename = \"model.pkl\"\n",
    "pickle.dump(model, open(model_filename, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading model succeeded\n"
     ]
    }
   ],
   "source": [
    "try : \n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name) # Add bucket name\n",
    "    blob_model = bucket.blob('m_fahd/model/model.pkl')\n",
    "    blob_model.upload_from_filename('model.pkl')\n",
    "\n",
    "    print (\"Uploading model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"dev_trial.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/41965541199/locations/us-central1/models/724187836076523520/operations/2968245335555571712\n",
      "Model created. Resource name: projects/41965541199/locations/us-central1/models/724187836076523520@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/41965541199/locations/us-central1/models/724187836076523520@1')\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project='dtidsus', location='us-central1')\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    display_name='fahd_model_000',\n",
    "    artifact_uri=\"gs://modul4/m_fahd/model/\",\n",
    "    serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.1-2:latest\",\n",
    ")\n",
    "\n",
    "model.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/41965541199/locations/us-central1/endpoints/8783753203209469952/operations/8980550838095183872\n",
      "Endpoint created. Resource name: projects/41965541199/locations/us-central1/endpoints/8783753203209469952\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/41965541199/locations/us-central1/endpoints/8783753203209469952')\n"
     ]
    }
   ],
   "source": [
    "# endpoint = aiplatform.Endpoint.create(\n",
    "#     display_name=\"jaya-endpoint-000\",\n",
    "#     project='dtidsus',\n",
    "#     location='us-central1',\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_replica_count: int = 1\n",
    "max_replica_count: int = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploying Model projects/41965541199/locations/us-central1/models/724187836076523520 to Endpoint : projects/41965541199/locations/us-central1/endpoints/8783753203209469952\n",
      "Deploy Endpoint model backing LRO: projects/41965541199/locations/us-central1/endpoints/8783753203209469952/operations/4965591770294386688\n",
      "Endpoint model deployed. Resource name: projects/41965541199/locations/us-central1/endpoints/8783753203209469952\n"
     ]
    }
   ],
   "source": [
    "endpoint.deploy( \n",
    "    model=model,\n",
    "    deployed_model_display_name='fahd_model_000',\n",
    "    machine_type='e2-standard-2',\n",
    "    min_replica_count=min_replica_count,\n",
    "    max_replica_count=max_replica_count,\n",
    "    sync=True, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#using endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predict your data with online prediction here \n",
    "PROJECT_ID = 'dtidsus'\n",
    "ENDPOINT_ID = \"projects/41965541199/locations/us-central1/endpoints/8783753203209469952\"\n",
    "REGION = 'us-central1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION: Prediction(predictions=[0.0], deployed_model_id='4624375482123550720', metadata=None, model_version_id='1', model_resource_name='projects/41965541199/locations/us-central1/models/724187836076523520', explanations=None)\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "endpoint = aiplatform.Endpoint(ENDPOINT_ID)\n",
    "prediction = endpoint.predict(instances=[[1, 1, 0, 0, 0, 1, 0, 0, 0, 60]])\n",
    "\n",
    "print(\"PREDICTION:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#manual file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download model succeeded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    storage_client = storage.Client(project=project_id)\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "    blob_model = bucket.blob('ilham/model/model.pkl')\n",
    "    blob_model.download_to_filename('model_new.pkl')\n",
    "\n",
    "    print (\"download model succeeded\")\n",
    "except:\n",
    "    raise TypeError(\"An exception occurred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = pickle.load(open('model_new.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = model_load.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
